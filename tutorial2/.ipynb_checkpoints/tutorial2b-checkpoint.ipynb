{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Walkthrough"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We spend a lot of money on education every year! In general, we believe that the more we spend, the better our schools are and the better our students do. But do we really know that?\n",
    "\n",
    "To adress these questions, we will spend today looking at a US education dataset and see what we can learn about indicators of student performance. In particular, we want to answer the question: are revenue, expenditure, or enrollment useful indicators to predict student performance on national exams?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data poking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start off by importing our data and seeing what we've got:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/states_edu.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1715, 25)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We downloaded this data off of <a href=\"https://www.kaggle.com/noriuk/us-education-datasets-unification-project\">Kaggle</a>, where they provide us with a _data dictionary_. A data dictionary describes a dataset -- it typically defines the columns, describes special values, explains missing values, etc.\n",
    "\n",
    "From our data dictionary, we are given that this dataset describes \"K-12 financial, enrollment, and achievement data in one place\". Each row is one state in one year, and includes variables for revenue categories, expenditure types, enrollment numbers, and exam scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRIMARY_KEY</th>\n",
       "      <th>STATE</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>ENROLL</th>\n",
       "      <th>TOTAL_REVENUE</th>\n",
       "      <th>FEDERAL_REVENUE</th>\n",
       "      <th>STATE_REVENUE</th>\n",
       "      <th>LOCAL_REVENUE</th>\n",
       "      <th>TOTAL_EXPENDITURE</th>\n",
       "      <th>INSTRUCTION_EXPENDITURE</th>\n",
       "      <th>...</th>\n",
       "      <th>GRADES_4_G</th>\n",
       "      <th>GRADES_8_G</th>\n",
       "      <th>GRADES_12_G</th>\n",
       "      <th>GRADES_1_8_G</th>\n",
       "      <th>GRADES_9_12_G</th>\n",
       "      <th>GRADES_ALL_G</th>\n",
       "      <th>AVG_MATH_4_SCORE</th>\n",
       "      <th>AVG_MATH_8_SCORE</th>\n",
       "      <th>AVG_READING_4_SCORE</th>\n",
       "      <th>AVG_READING_8_SCORE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1992_ALABAMA</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>1992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2678885.0</td>\n",
       "      <td>304177.0</td>\n",
       "      <td>1659028.0</td>\n",
       "      <td>715680.0</td>\n",
       "      <td>2653798.0</td>\n",
       "      <td>1481703.0</td>\n",
       "      <td>...</td>\n",
       "      <td>57948.0</td>\n",
       "      <td>58025.0</td>\n",
       "      <td>41167.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>731634.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1992_ALASKA</td>\n",
       "      <td>ALASKA</td>\n",
       "      <td>1992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1049591.0</td>\n",
       "      <td>106780.0</td>\n",
       "      <td>720711.0</td>\n",
       "      <td>222100.0</td>\n",
       "      <td>972488.0</td>\n",
       "      <td>498362.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9748.0</td>\n",
       "      <td>8789.0</td>\n",
       "      <td>6714.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>122487.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1992_ARIZONA</td>\n",
       "      <td>ARIZONA</td>\n",
       "      <td>1992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3258079.0</td>\n",
       "      <td>297888.0</td>\n",
       "      <td>1369815.0</td>\n",
       "      <td>1590376.0</td>\n",
       "      <td>3401580.0</td>\n",
       "      <td>1435908.0</td>\n",
       "      <td>...</td>\n",
       "      <td>55433.0</td>\n",
       "      <td>49081.0</td>\n",
       "      <td>37410.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>673477.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1992_ARKANSAS</td>\n",
       "      <td>ARKANSAS</td>\n",
       "      <td>1992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1711959.0</td>\n",
       "      <td>178571.0</td>\n",
       "      <td>958785.0</td>\n",
       "      <td>574603.0</td>\n",
       "      <td>1743022.0</td>\n",
       "      <td>964323.0</td>\n",
       "      <td>...</td>\n",
       "      <td>34632.0</td>\n",
       "      <td>36011.0</td>\n",
       "      <td>27651.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>441490.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1992_CALIFORNIA</td>\n",
       "      <td>CALIFORNIA</td>\n",
       "      <td>1992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26260025.0</td>\n",
       "      <td>2072470.0</td>\n",
       "      <td>16546514.0</td>\n",
       "      <td>7641041.0</td>\n",
       "      <td>27138832.0</td>\n",
       "      <td>14358922.0</td>\n",
       "      <td>...</td>\n",
       "      <td>418418.0</td>\n",
       "      <td>363296.0</td>\n",
       "      <td>270675.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5254844.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       PRIMARY_KEY       STATE  YEAR  ENROLL  TOTAL_REVENUE  FEDERAL_REVENUE  \\\n",
       "0     1992_ALABAMA     ALABAMA  1992     NaN      2678885.0         304177.0   \n",
       "1      1992_ALASKA      ALASKA  1992     NaN      1049591.0         106780.0   \n",
       "2     1992_ARIZONA     ARIZONA  1992     NaN      3258079.0         297888.0   \n",
       "3    1992_ARKANSAS    ARKANSAS  1992     NaN      1711959.0         178571.0   \n",
       "4  1992_CALIFORNIA  CALIFORNIA  1992     NaN     26260025.0        2072470.0   \n",
       "\n",
       "   STATE_REVENUE  LOCAL_REVENUE  TOTAL_EXPENDITURE  INSTRUCTION_EXPENDITURE  \\\n",
       "0      1659028.0       715680.0          2653798.0                1481703.0   \n",
       "1       720711.0       222100.0           972488.0                 498362.0   \n",
       "2      1369815.0      1590376.0          3401580.0                1435908.0   \n",
       "3       958785.0       574603.0          1743022.0                 964323.0   \n",
       "4     16546514.0      7641041.0         27138832.0               14358922.0   \n",
       "\n",
       "   ...  GRADES_4_G  GRADES_8_G  GRADES_12_G  GRADES_1_8_G  GRADES_9_12_G  \\\n",
       "0  ...     57948.0     58025.0      41167.0           NaN            NaN   \n",
       "1  ...      9748.0      8789.0       6714.0           NaN            NaN   \n",
       "2  ...     55433.0     49081.0      37410.0           NaN            NaN   \n",
       "3  ...     34632.0     36011.0      27651.0           NaN            NaN   \n",
       "4  ...    418418.0    363296.0     270675.0           NaN            NaN   \n",
       "\n",
       "   GRADES_ALL_G  AVG_MATH_4_SCORE  AVG_MATH_8_SCORE  AVG_READING_4_SCORE  \\\n",
       "0      731634.0             208.0             252.0                207.0   \n",
       "1      122487.0               NaN               NaN                  NaN   \n",
       "2      673477.0             215.0             265.0                209.0   \n",
       "3      441490.0             210.0             256.0                211.0   \n",
       "4     5254844.0             208.0             261.0                202.0   \n",
       "\n",
       "   AVG_READING_8_SCORE  \n",
       "0                  NaN  \n",
       "1                  NaN  \n",
       "2                  NaN  \n",
       "3                  NaN  \n",
       "4                  NaN  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PRIMARY_KEY', 'STATE', 'YEAR', 'ENROLL', 'TOTAL_REVENUE',\n",
       "       'FEDERAL_REVENUE', 'STATE_REVENUE', 'LOCAL_REVENUE',\n",
       "       'TOTAL_EXPENDITURE', 'INSTRUCTION_EXPENDITURE',\n",
       "       'SUPPORT_SERVICES_EXPENDITURE', 'OTHER_EXPENDITURE',\n",
       "       'CAPITAL_OUTLAY_EXPENDITURE', 'GRADES_PK_G', 'GRADES_KG_G',\n",
       "       'GRADES_4_G', 'GRADES_8_G', 'GRADES_12_G', 'GRADES_1_8_G',\n",
       "       'GRADES_9_12_G', 'GRADES_ALL_G', 'AVG_MATH_4_SCORE', 'AVG_MATH_8_SCORE',\n",
       "       'AVG_READING_4_SCORE', 'AVG_READING_8_SCORE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's rename our columns to make them more intuitive\n",
    "df.rename({\n",
    "    'GRADES_PK_G':'ENROLL_PREK',\n",
    "    'GRADES_KG_G':'ENROLL_KINDER',\n",
    "    'GRADES_4_G':'ENROLL_4',\n",
    "    'GRADES_8_G':'ENROLL_8',\n",
    "    'GRADES_12_G':'ENROLL_12',\n",
    "    'GRADES_1_8_G':'ENROLL_PRIMARY',\n",
    "    'GRADES_9_12_G':'ENROLL_HS',\n",
    "    'GRADES_ALL_G':'ENROLL_ALL',\n",
    "    'ENROLL':'ENROLL_ALL_EST'\n",
    "    },\n",
    "    axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRIMARY_KEY</th>\n",
       "      <th>STATE</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>ENROLL_ALL_EST</th>\n",
       "      <th>TOTAL_REVENUE</th>\n",
       "      <th>FEDERAL_REVENUE</th>\n",
       "      <th>STATE_REVENUE</th>\n",
       "      <th>LOCAL_REVENUE</th>\n",
       "      <th>TOTAL_EXPENDITURE</th>\n",
       "      <th>INSTRUCTION_EXPENDITURE</th>\n",
       "      <th>...</th>\n",
       "      <th>ENROLL_4</th>\n",
       "      <th>ENROLL_8</th>\n",
       "      <th>ENROLL_12</th>\n",
       "      <th>ENROLL_PRIMARY</th>\n",
       "      <th>ENROLL_HS</th>\n",
       "      <th>ENROLL_ALL</th>\n",
       "      <th>AVG_MATH_4_SCORE</th>\n",
       "      <th>AVG_MATH_8_SCORE</th>\n",
       "      <th>AVG_READING_4_SCORE</th>\n",
       "      <th>AVG_READING_8_SCORE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1992_ALABAMA</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>1992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2678885.0</td>\n",
       "      <td>304177.0</td>\n",
       "      <td>1659028.0</td>\n",
       "      <td>715680.0</td>\n",
       "      <td>2653798.0</td>\n",
       "      <td>1481703.0</td>\n",
       "      <td>...</td>\n",
       "      <td>57948.0</td>\n",
       "      <td>58025.0</td>\n",
       "      <td>41167.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>731634.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1992_ALASKA</td>\n",
       "      <td>ALASKA</td>\n",
       "      <td>1992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1049591.0</td>\n",
       "      <td>106780.0</td>\n",
       "      <td>720711.0</td>\n",
       "      <td>222100.0</td>\n",
       "      <td>972488.0</td>\n",
       "      <td>498362.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9748.0</td>\n",
       "      <td>8789.0</td>\n",
       "      <td>6714.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>122487.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1992_ARIZONA</td>\n",
       "      <td>ARIZONA</td>\n",
       "      <td>1992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3258079.0</td>\n",
       "      <td>297888.0</td>\n",
       "      <td>1369815.0</td>\n",
       "      <td>1590376.0</td>\n",
       "      <td>3401580.0</td>\n",
       "      <td>1435908.0</td>\n",
       "      <td>...</td>\n",
       "      <td>55433.0</td>\n",
       "      <td>49081.0</td>\n",
       "      <td>37410.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>673477.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1992_ARKANSAS</td>\n",
       "      <td>ARKANSAS</td>\n",
       "      <td>1992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1711959.0</td>\n",
       "      <td>178571.0</td>\n",
       "      <td>958785.0</td>\n",
       "      <td>574603.0</td>\n",
       "      <td>1743022.0</td>\n",
       "      <td>964323.0</td>\n",
       "      <td>...</td>\n",
       "      <td>34632.0</td>\n",
       "      <td>36011.0</td>\n",
       "      <td>27651.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>441490.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1992_CALIFORNIA</td>\n",
       "      <td>CALIFORNIA</td>\n",
       "      <td>1992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26260025.0</td>\n",
       "      <td>2072470.0</td>\n",
       "      <td>16546514.0</td>\n",
       "      <td>7641041.0</td>\n",
       "      <td>27138832.0</td>\n",
       "      <td>14358922.0</td>\n",
       "      <td>...</td>\n",
       "      <td>418418.0</td>\n",
       "      <td>363296.0</td>\n",
       "      <td>270675.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5254844.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       PRIMARY_KEY       STATE  YEAR  ENROLL_ALL_EST  TOTAL_REVENUE  \\\n",
       "0     1992_ALABAMA     ALABAMA  1992             NaN      2678885.0   \n",
       "1      1992_ALASKA      ALASKA  1992             NaN      1049591.0   \n",
       "2     1992_ARIZONA     ARIZONA  1992             NaN      3258079.0   \n",
       "3    1992_ARKANSAS    ARKANSAS  1992             NaN      1711959.0   \n",
       "4  1992_CALIFORNIA  CALIFORNIA  1992             NaN     26260025.0   \n",
       "\n",
       "   FEDERAL_REVENUE  STATE_REVENUE  LOCAL_REVENUE  TOTAL_EXPENDITURE  \\\n",
       "0         304177.0      1659028.0       715680.0          2653798.0   \n",
       "1         106780.0       720711.0       222100.0           972488.0   \n",
       "2         297888.0      1369815.0      1590376.0          3401580.0   \n",
       "3         178571.0       958785.0       574603.0          1743022.0   \n",
       "4        2072470.0     16546514.0      7641041.0         27138832.0   \n",
       "\n",
       "   INSTRUCTION_EXPENDITURE  ...  ENROLL_4  ENROLL_8  ENROLL_12  \\\n",
       "0                1481703.0  ...   57948.0   58025.0    41167.0   \n",
       "1                 498362.0  ...    9748.0    8789.0     6714.0   \n",
       "2                1435908.0  ...   55433.0   49081.0    37410.0   \n",
       "3                 964323.0  ...   34632.0   36011.0    27651.0   \n",
       "4               14358922.0  ...  418418.0  363296.0   270675.0   \n",
       "\n",
       "   ENROLL_PRIMARY  ENROLL_HS  ENROLL_ALL  AVG_MATH_4_SCORE  AVG_MATH_8_SCORE  \\\n",
       "0             NaN        NaN    731634.0             208.0             252.0   \n",
       "1             NaN        NaN    122487.0               NaN               NaN   \n",
       "2             NaN        NaN    673477.0             215.0             265.0   \n",
       "3             NaN        NaN    441490.0             210.0             256.0   \n",
       "4             NaN        NaN   5254844.0             208.0             261.0   \n",
       "\n",
       "   AVG_READING_4_SCORE  AVG_READING_8_SCORE  \n",
       "0                207.0                  NaN  \n",
       "1                  NaN                  NaN  \n",
       "2                209.0                  NaN  \n",
       "3                211.0                  NaN  \n",
       "4                202.0                  NaN  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking closer at the data, there are a lot of 'NaN' values... what are those?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is a numpy value which represents missnig or invalid data (not-a-number)\n",
    "np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# it is treated as a float, so it is easily compatible with numpy and pandas\n",
    "type(np.NaN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily find and describe missing values with pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PRIMARY_KEY                        0\n",
       "STATE                              0\n",
       "YEAR                               0\n",
       "ENROLL_ALL_EST                   491\n",
       "TOTAL_REVENUE                    440\n",
       "FEDERAL_REVENUE                  440\n",
       "STATE_REVENUE                    440\n",
       "LOCAL_REVENUE                    440\n",
       "TOTAL_EXPENDITURE                440\n",
       "INSTRUCTION_EXPENDITURE          440\n",
       "SUPPORT_SERVICES_EXPENDITURE     440\n",
       "OTHER_EXPENDITURE                491\n",
       "CAPITAL_OUTLAY_EXPENDITURE       440\n",
       "ENROLL_PREK                      173\n",
       "ENROLL_KINDER                     83\n",
       "ENROLL_4                          83\n",
       "ENROLL_8                          83\n",
       "ENROLL_12                         83\n",
       "ENROLL_PRIMARY                   695\n",
       "ENROLL_HS                        644\n",
       "ENROLL_ALL                        83\n",
       "AVG_MATH_4_SCORE                1150\n",
       "AVG_MATH_8_SCORE                1113\n",
       "AVG_READING_4_SCORE             1065\n",
       "AVG_READING_8_SCORE             1153\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this will print the number of missing values in each column\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PRIMARY_KEY                     1715\n",
       "STATE                           1715\n",
       "YEAR                            1715\n",
       "ENROLL_ALL_EST                  1224\n",
       "TOTAL_REVENUE                   1275\n",
       "FEDERAL_REVENUE                 1275\n",
       "STATE_REVENUE                   1275\n",
       "LOCAL_REVENUE                   1275\n",
       "TOTAL_EXPENDITURE               1275\n",
       "INSTRUCTION_EXPENDITURE         1275\n",
       "SUPPORT_SERVICES_EXPENDITURE    1275\n",
       "OTHER_EXPENDITURE               1224\n",
       "CAPITAL_OUTLAY_EXPENDITURE      1275\n",
       "ENROLL_PREK                     1542\n",
       "ENROLL_KINDER                   1632\n",
       "ENROLL_4                        1632\n",
       "ENROLL_8                        1632\n",
       "ENROLL_12                       1632\n",
       "ENROLL_PRIMARY                  1020\n",
       "ENROLL_HS                       1071\n",
       "ENROLL_ALL                      1632\n",
       "AVG_MATH_4_SCORE                 565\n",
       "AVG_MATH_8_SCORE                 602\n",
       "AVG_READING_4_SCORE              650\n",
       "AVG_READING_8_SCORE              562\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this will print the number of valid values in each column\n",
    "df.notna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PRIMARY_KEY                     1715\n",
       "STATE                           1715\n",
       "YEAR                            1715\n",
       "ENROLL_ALL_EST                  1224\n",
       "TOTAL_REVENUE                   1275\n",
       "FEDERAL_REVENUE                 1275\n",
       "STATE_REVENUE                   1275\n",
       "LOCAL_REVENUE                   1275\n",
       "TOTAL_EXPENDITURE               1275\n",
       "INSTRUCTION_EXPENDITURE         1275\n",
       "SUPPORT_SERVICES_EXPENDITURE    1275\n",
       "OTHER_EXPENDITURE               1224\n",
       "CAPITAL_OUTLAY_EXPENDITURE      1275\n",
       "ENROLL_PREK                     1542\n",
       "ENROLL_KINDER                   1632\n",
       "ENROLL_4                        1632\n",
       "ENROLL_8                        1632\n",
       "ENROLL_12                       1632\n",
       "ENROLL_PRIMARY                  1020\n",
       "ENROLL_HS                       1071\n",
       "ENROLL_ALL                      1632\n",
       "AVG_MATH_4_SCORE                 565\n",
       "AVG_MATH_8_SCORE                 602\n",
       "AVG_READING_4_SCORE              650\n",
       "AVG_READING_8_SCORE              562\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# notice that pandas will often ignore missing values by default\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way we can deal with missing values is by dropping rows with any null value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRIMARY_KEY</th>\n",
       "      <th>STATE</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>ENROLL_ALL_EST</th>\n",
       "      <th>TOTAL_REVENUE</th>\n",
       "      <th>FEDERAL_REVENUE</th>\n",
       "      <th>STATE_REVENUE</th>\n",
       "      <th>LOCAL_REVENUE</th>\n",
       "      <th>TOTAL_EXPENDITURE</th>\n",
       "      <th>INSTRUCTION_EXPENDITURE</th>\n",
       "      <th>...</th>\n",
       "      <th>ENROLL_4</th>\n",
       "      <th>ENROLL_8</th>\n",
       "      <th>ENROLL_12</th>\n",
       "      <th>ENROLL_PRIMARY</th>\n",
       "      <th>ENROLL_HS</th>\n",
       "      <th>ENROLL_ALL</th>\n",
       "      <th>AVG_MATH_4_SCORE</th>\n",
       "      <th>AVG_MATH_8_SCORE</th>\n",
       "      <th>AVG_READING_4_SCORE</th>\n",
       "      <th>AVG_READING_8_SCORE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>2003_ALABAMA</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>2003</td>\n",
       "      <td>727900.0</td>\n",
       "      <td>5196054.0</td>\n",
       "      <td>567704.0</td>\n",
       "      <td>2966981.0</td>\n",
       "      <td>1661369.0</td>\n",
       "      <td>5298932.0</td>\n",
       "      <td>2817111.0</td>\n",
       "      <td>...</td>\n",
       "      <td>57323.0</td>\n",
       "      <td>59663.0</td>\n",
       "      <td>42005.0</td>\n",
       "      <td>466920.0</td>\n",
       "      <td>205907.0</td>\n",
       "      <td>731220.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>262.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>253.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>2003_ALASKA</td>\n",
       "      <td>ALASKA</td>\n",
       "      <td>2003</td>\n",
       "      <td>133303.0</td>\n",
       "      <td>1425948.0</td>\n",
       "      <td>259423.0</td>\n",
       "      <td>813371.0</td>\n",
       "      <td>353154.0</td>\n",
       "      <td>1610289.0</td>\n",
       "      <td>763525.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10115.0</td>\n",
       "      <td>11140.0</td>\n",
       "      <td>8651.0</td>\n",
       "      <td>82337.0</td>\n",
       "      <td>40238.0</td>\n",
       "      <td>133933.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>279.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>256.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>2003_ARIZONA</td>\n",
       "      <td>ARIZONA</td>\n",
       "      <td>2003</td>\n",
       "      <td>875111.0</td>\n",
       "      <td>6529894.0</td>\n",
       "      <td>740579.0</td>\n",
       "      <td>2912629.0</td>\n",
       "      <td>2876686.0</td>\n",
       "      <td>6210287.0</td>\n",
       "      <td>2810907.0</td>\n",
       "      <td>...</td>\n",
       "      <td>76207.0</td>\n",
       "      <td>76376.0</td>\n",
       "      <td>68815.0</td>\n",
       "      <td>613442.0</td>\n",
       "      <td>307272.0</td>\n",
       "      <td>1012068.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>271.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>255.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>2003_ARKANSAS</td>\n",
       "      <td>ARKANSAS</td>\n",
       "      <td>2003</td>\n",
       "      <td>450158.0</td>\n",
       "      <td>3241275.0</td>\n",
       "      <td>379947.0</td>\n",
       "      <td>2394336.0</td>\n",
       "      <td>466992.0</td>\n",
       "      <td>3242799.0</td>\n",
       "      <td>1768713.0</td>\n",
       "      <td>...</td>\n",
       "      <td>34070.0</td>\n",
       "      <td>37004.0</td>\n",
       "      <td>28840.0</td>\n",
       "      <td>281834.0</td>\n",
       "      <td>132712.0</td>\n",
       "      <td>454523.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>258.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>2003_CALIFORNIA</td>\n",
       "      <td>CALIFORNIA</td>\n",
       "      <td>2003</td>\n",
       "      <td>6226552.0</td>\n",
       "      <td>59815855.0</td>\n",
       "      <td>5795655.0</td>\n",
       "      <td>33617766.0</td>\n",
       "      <td>20402434.0</td>\n",
       "      <td>59749885.0</td>\n",
       "      <td>29561563.0</td>\n",
       "      <td>...</td>\n",
       "      <td>493415.0</td>\n",
       "      <td>500143.0</td>\n",
       "      <td>395194.0</td>\n",
       "      <td>3929869.0</td>\n",
       "      <td>1854518.0</td>\n",
       "      <td>6413867.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>251.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1219</th>\n",
       "      <td>2015_VIRGINIA</td>\n",
       "      <td>VIRGINIA</td>\n",
       "      <td>2015</td>\n",
       "      <td>1279867.0</td>\n",
       "      <td>15857524.0</td>\n",
       "      <td>1012205.0</td>\n",
       "      <td>6240349.0</td>\n",
       "      <td>8604970.0</td>\n",
       "      <td>16113212.0</td>\n",
       "      <td>8755896.0</td>\n",
       "      <td>...</td>\n",
       "      <td>96851.0</td>\n",
       "      <td>95221.0</td>\n",
       "      <td>90391.0</td>\n",
       "      <td>772414.0</td>\n",
       "      <td>386781.0</td>\n",
       "      <td>1283590.0</td>\n",
       "      <td>247.0</td>\n",
       "      <td>288.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>267.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1220</th>\n",
       "      <td>2015_WASHINGTON</td>\n",
       "      <td>WASHINGTON</td>\n",
       "      <td>2015</td>\n",
       "      <td>1072359.0</td>\n",
       "      <td>13709442.0</td>\n",
       "      <td>1036422.0</td>\n",
       "      <td>8293812.0</td>\n",
       "      <td>4379208.0</td>\n",
       "      <td>13630138.0</td>\n",
       "      <td>6508964.0</td>\n",
       "      <td>...</td>\n",
       "      <td>82404.0</td>\n",
       "      <td>79483.0</td>\n",
       "      <td>89258.0</td>\n",
       "      <td>656797.0</td>\n",
       "      <td>336808.0</td>\n",
       "      <td>1087030.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>287.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>267.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1221</th>\n",
       "      <td>2015_WEST_VIRGINIA</td>\n",
       "      <td>WEST_VIRGINIA</td>\n",
       "      <td>2015</td>\n",
       "      <td>279565.0</td>\n",
       "      <td>3478401.0</td>\n",
       "      <td>362959.0</td>\n",
       "      <td>1979466.0</td>\n",
       "      <td>1135976.0</td>\n",
       "      <td>3466981.0</td>\n",
       "      <td>1819903.0</td>\n",
       "      <td>...</td>\n",
       "      <td>19814.0</td>\n",
       "      <td>20426.0</td>\n",
       "      <td>18432.0</td>\n",
       "      <td>162070.0</td>\n",
       "      <td>80142.0</td>\n",
       "      <td>277452.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>271.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>260.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1222</th>\n",
       "      <td>2015_WISCONSIN</td>\n",
       "      <td>WISCONSIN</td>\n",
       "      <td>2015</td>\n",
       "      <td>861813.0</td>\n",
       "      <td>11637376.0</td>\n",
       "      <td>814385.0</td>\n",
       "      <td>5869265.0</td>\n",
       "      <td>4953726.0</td>\n",
       "      <td>11553677.0</td>\n",
       "      <td>5723474.0</td>\n",
       "      <td>...</td>\n",
       "      <td>60999.0</td>\n",
       "      <td>61084.0</td>\n",
       "      <td>66253.0</td>\n",
       "      <td>489919.0</td>\n",
       "      <td>263896.0</td>\n",
       "      <td>867800.0</td>\n",
       "      <td>243.0</td>\n",
       "      <td>289.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>270.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1223</th>\n",
       "      <td>2015_WYOMING</td>\n",
       "      <td>WYOMING</td>\n",
       "      <td>2015</td>\n",
       "      <td>93867.0</td>\n",
       "      <td>1962874.0</td>\n",
       "      <td>120290.0</td>\n",
       "      <td>1116917.0</td>\n",
       "      <td>725667.0</td>\n",
       "      <td>1942406.0</td>\n",
       "      <td>895910.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7551.0</td>\n",
       "      <td>6902.0</td>\n",
       "      <td>6299.0</td>\n",
       "      <td>59453.0</td>\n",
       "      <td>26914.0</td>\n",
       "      <td>94717.0</td>\n",
       "      <td>247.0</td>\n",
       "      <td>287.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>269.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>355 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             PRIMARY_KEY          STATE  YEAR  ENROLL_ALL_EST  TOTAL_REVENUE  \\\n",
       "561         2003_ALABAMA        ALABAMA  2003        727900.0      5196054.0   \n",
       "562          2003_ALASKA         ALASKA  2003        133303.0      1425948.0   \n",
       "563         2003_ARIZONA        ARIZONA  2003        875111.0      6529894.0   \n",
       "564        2003_ARKANSAS       ARKANSAS  2003        450158.0      3241275.0   \n",
       "565      2003_CALIFORNIA     CALIFORNIA  2003       6226552.0     59815855.0   \n",
       "...                  ...            ...   ...             ...            ...   \n",
       "1219       2015_VIRGINIA       VIRGINIA  2015       1279867.0     15857524.0   \n",
       "1220     2015_WASHINGTON     WASHINGTON  2015       1072359.0     13709442.0   \n",
       "1221  2015_WEST_VIRGINIA  WEST_VIRGINIA  2015        279565.0      3478401.0   \n",
       "1222      2015_WISCONSIN      WISCONSIN  2015        861813.0     11637376.0   \n",
       "1223        2015_WYOMING        WYOMING  2015         93867.0      1962874.0   \n",
       "\n",
       "      FEDERAL_REVENUE  STATE_REVENUE  LOCAL_REVENUE  TOTAL_EXPENDITURE  \\\n",
       "561          567704.0      2966981.0      1661369.0          5298932.0   \n",
       "562          259423.0       813371.0       353154.0          1610289.0   \n",
       "563          740579.0      2912629.0      2876686.0          6210287.0   \n",
       "564          379947.0      2394336.0       466992.0          3242799.0   \n",
       "565         5795655.0     33617766.0     20402434.0         59749885.0   \n",
       "...               ...            ...            ...                ...   \n",
       "1219        1012205.0      6240349.0      8604970.0         16113212.0   \n",
       "1220        1036422.0      8293812.0      4379208.0         13630138.0   \n",
       "1221         362959.0      1979466.0      1135976.0          3466981.0   \n",
       "1222         814385.0      5869265.0      4953726.0         11553677.0   \n",
       "1223         120290.0      1116917.0       725667.0          1942406.0   \n",
       "\n",
       "      INSTRUCTION_EXPENDITURE  ...  ENROLL_4  ENROLL_8  ENROLL_12  \\\n",
       "561                 2817111.0  ...   57323.0   59663.0    42005.0   \n",
       "562                  763525.0  ...   10115.0   11140.0     8651.0   \n",
       "563                 2810907.0  ...   76207.0   76376.0    68815.0   \n",
       "564                 1768713.0  ...   34070.0   37004.0    28840.0   \n",
       "565                29561563.0  ...  493415.0  500143.0   395194.0   \n",
       "...                       ...  ...       ...       ...        ...   \n",
       "1219                8755896.0  ...   96851.0   95221.0    90391.0   \n",
       "1220                6508964.0  ...   82404.0   79483.0    89258.0   \n",
       "1221                1819903.0  ...   19814.0   20426.0    18432.0   \n",
       "1222                5723474.0  ...   60999.0   61084.0    66253.0   \n",
       "1223                 895910.0  ...    7551.0    6902.0     6299.0   \n",
       "\n",
       "      ENROLL_PRIMARY  ENROLL_HS  ENROLL_ALL  AVG_MATH_4_SCORE  \\\n",
       "561         466920.0   205907.0    731220.0             223.0   \n",
       "562          82337.0    40238.0    133933.0             233.0   \n",
       "563         613442.0   307272.0   1012068.0             229.0   \n",
       "564         281834.0   132712.0    454523.0             229.0   \n",
       "565        3929869.0  1854518.0   6413867.0             227.0   \n",
       "...              ...        ...         ...               ...   \n",
       "1219        772414.0   386781.0   1283590.0             247.0   \n",
       "1220        656797.0   336808.0   1087030.0             245.0   \n",
       "1221        162070.0    80142.0    277452.0             235.0   \n",
       "1222        489919.0   263896.0    867800.0             243.0   \n",
       "1223         59453.0    26914.0     94717.0             247.0   \n",
       "\n",
       "      AVG_MATH_8_SCORE  AVG_READING_4_SCORE  AVG_READING_8_SCORE  \n",
       "561              262.0                207.0                253.0  \n",
       "562              279.0                212.0                256.0  \n",
       "563              271.0                209.0                255.0  \n",
       "564              266.0                214.0                258.0  \n",
       "565              267.0                206.0                251.0  \n",
       "...                ...                  ...                  ...  \n",
       "1219             288.0                229.0                267.0  \n",
       "1220             287.0                226.0                267.0  \n",
       "1221             271.0                216.0                260.0  \n",
       "1222             289.0                223.0                270.0  \n",
       "1223             287.0                228.0                269.0  \n",
       "\n",
       "[355 rows x 25 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# by default, dropna will remove all rows with at least 1 nan\n",
    "df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping rows with any nan leaves us only 355 rows -- do we actually need all our data to be complete? Which rows are actually important?\n",
    "\n",
    "That depends on what you want to do with the data! \n",
    "\n",
    "Let's say I have a sister in 7th grade so I am particularly interested in learning how well 8th graders read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I want all my rows to have average reading 8 score data, so I remove rows missing AVG_READING_8_SCORE\n",
    "df.dropna(subset=['AVG_READING_8_SCORE'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way of dealing with missing values is filling them in. \n",
    "\n",
    "In our data, we have two columns representing total student enrollment: 'ENROLL_ALL_EST' and 'ENROLL_ALL'. We also have enrollment data divided by school group. Let's see if we can use them to fill each other in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.ENROLL_ALL.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first let's check to see if the individual enrollments actually sum up to total enrollment\n",
    "(df.ENROLL_ALL-df.ENROLL_PREK-df.ENROLL_KINDER-df.ENROLL_PRIMARY-df.ENROLL_HS).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enrollment differences as a percent\n",
    "((df.ENROLL_ALL-df.ENROLL_PREK-df.ENROLL_KINDER-df.ENROLL_PRIMARY-df.ENROLL_HS)/df.ENROLL_ALL*100).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ENROLL_ALL'] = df['ENROLL_ALL'].fillna(df.ENROLL_PREK+df.ENROLL_PRIMARY+df.ENROLL_HS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this didn't actually do anything!\n",
    "df.ENROLL_ALL.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turns out, data missing ENROLL_ALL is also missing all other enrollment data\n",
    "df[df.ENROLL_ALL.isna()][['ENROLL_PREK','ENROLL_PRIMARY','ENROLL_HS','ENROLL_ALL_EST']].notna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# but there are rows with enrollment estimates\n",
    "df[df.ENROLL_ALL_EST.isna()].ENROLL_ALL.notna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's see if we can fill these in\n",
    "((df.ENROLL_ALL - df.ENROLL_ALL_EST)/df.ENROLL_ALL).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since the average error between the enrollments is ~2%, I'm going to go ahead and fill in the missing estimates\n",
    "df.ENROLL_ALL_EST = df.ENROLL_ALL_EST.fillna(df.ENROLL_ALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.ENROLL_ALL_EST.isna()].ENROLL_ALL.notna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we just did was data cleanup! Most data scientists will tell you that data cleanup and preprocessing will take >60% of the total time for a given project... we just gave you a small taster here but you'll be seeing a lot more of it :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something else you'll see a lot of is feature engineering and selection. This is where we decide what data is actually useful to analyze the problem at hand. \n",
    "\n",
    "Here are some common methods of modifying features:\n",
    "\n",
    "* Standardization\n",
    ">helps some models account for different magnitude features, e.g. revenue is ~10x bigger than enrollment on average, but that doesn't make it more important\n",
    "* Binning\n",
    ">reduces the importance of small differences in data, e.g. exact enrollment probably doesn't matter, but there may still be a difference between 'small', 'medium', and 'large' schools\n",
    "* Combining features\n",
    ">combinations of features may matter more than the features on their own, e.g. educational expenditure as a percent of total expenditure is more informative about a state's priorities (states aren't all the same size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In this case, we know our data is on the state level and also longitudinal (over time). This format introduces a lot of complications. For example, the state of California will obviously spend more than New Jersey becuase they have more people... how can we account for this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's create a new variable which represents expenditure per student\n",
    "df['SUPPORT_SERVICES_EXPENDITURE_PER_STUDENT'] = df['SUPPORT_SERVICES_EXPENDITURE'] / df['ENROLL_ALL']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's do some EDA (exploratory data analysis)!\n",
    "\n",
    "First let's look at 8th grade reading score on its own:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note - this test is scored out of 500 according to the NAEP website\n",
    "df.AVG_READING_8_SCORE.hist()\n",
    "plt.xlabel('score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of 8th grade reading scores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('YEAR').AVG_READING_8_SCORE.mean().plot()\n",
    "plt.ylabel('SCORE')\n",
    "plt.title('8th grade reading score over time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('YEAR').groupby('STATE').AVG_READING_8_SCORE.plot()\n",
    "plt.ylabel('SCORE')\n",
    "plt.title('8th grade reading score over time, by state')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What other variables are related to 8th grade reading?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot.scatter(x='ENROLL_8',y='AVG_READING_8_SCORE')\n",
    "plt.xlabel('8th grade enrollment')\n",
    "plt.ylabel('8th grade reading score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot.scatter(x='STATE_REVENUE',y='AVG_READING_8_SCORE')\n",
    "plt.xlabel('state revenue')\n",
    "plt.ylabel('8th grade reading score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot.scatter(x='INSTRUCTION_EXPENDITURE',y='AVG_READING_8_SCORE')\n",
    "plt.xlabel('instruction expenditure')\n",
    "plt.ylabel('8th grade reading score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot.scatter(x='AVG_READING_4_SCORE',y='AVG_READING_8_SCORE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot.scatter(x='AVG_MATH_8_SCORE',y='AVG_READING_8_SCORE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now that we know a bit about the data, what do we want to do with it? How am I going to frame this as a _machine learning_ project?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now a quick intro to machine learning!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, I can't teach machine learning in a Saturday afternoon :( For this tutorial, we're going to practice a simple _supervised learning_ problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Machine learning workflow:**\n",
    "<img src=https://miro.medium.com/proxy/1*KzmIUYPmxgEHhXX7SlbP4w.jpeg width=500></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Supervised learning:**\n",
    "<img src=https://miro.medium.com/max/1050/1*-fniNC8gWI34qLAiBzgGZA.png width=800></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So how do we frame our research question as a ML problem?\n",
    "\n",
    "I already said I'm most interested in 8th grade reading scores, so I want to make that my outcome variable (i.e. what I'm trying to predict). Based on my background knowledge as well as EDA from earlier steps, I think that 'TOTAL_REVENUE', 'ENROLL_8', 'YEAR', and 'SUPPORT_SERVICES_EXPENDITURE_PER_STUDENT' would be interesting predictors to look at, so I will pick those as my input features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_train_split randomly splits the data into two parts -- \n",
    "# one for training the model (it uses this data to learn patterns)\n",
    "# and one for testing the model (to make sure it performs well on data it hasn't seen before)\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['TOTAL_REVENUE','ENROLL_8','SUPPORT_SERVICES_EXPENDITURE_PER_STUDENT','YEAR']].dropna()\n",
    "y = df.loc[X.index]['AVG_READING_8_SCORE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the test_size parameter defines what % of data is set aside for testing\n",
    "# random_state ensures that I get the same results each time I run the code\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to create and train a model! For simplicity, I'm going to use sklearn's LinearRegression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we are doing here is called _multilinear regression_. This just means that we are using multiple input variables to predict our outcome variable.\n",
    "\n",
    "Let's say there are $k$ of these variables, named $x_1$ through $x_k$ (here, I have $k=4$, $x_1$ = total_revenue, $x_2$ = enroll_8, etc.)\n",
    "\n",
    "\n",
    "$y_{predicted} = intercept + coef[0] * x_1 + coef[1] * x_2 + ... + coef[k-1] * x_k$\n",
    "\n",
    "Notice there are exactly $k$ coefficients as well. The way we interpret each coefficient is relative to the step size of the associated variable, with all other variables held constant. For example, if $coef[0]=20$, we say: \n",
    "'with all other variables held constant, a $1 change in total revenue results in a 20-point increase in reading score, on average'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.intercept_)\n",
    "print(model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R**2 value describes how well a linear model fits the data\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean error\n",
    "np.mean(model.predict(X_test)-y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean absolute error\n",
    "np.mean(np.abs(model.predict(X_test)-y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# root mean squared error -- penalizes large errors\n",
    "np.mean((model.predict(X_test)-y_test)**2)**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing data in multiple dimensions is really hard, both technically and intuitively. Below, we try to understand our performance by visualizing one variable at a time. Like we said before, when we look at one variable, we assume all others are held constant. This is not typically true in practice, however, so some of our results may look strange..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quickly visualize results\n",
    "col_name = 'TOTAL_REVENUE'\n",
    "col_index = X_train.columns.get_loc(col_name)\n",
    "\n",
    "f = plt.figure(figsize=(12,6))\n",
    "plt.scatter(X_train[col_name], y_train, color = \"red\")\n",
    "plt.scatter(X_train[col_name], model.predict(X_train), color = \"green\")\n",
    "plt.scatter(X_test[col_name], model.predict(X_test), color = \"blue\")\n",
    "\n",
    "new_x = np.linspace(X_train[col_name].min(),X_train[col_name].max(),100)\n",
    "intercept = model.predict([X_train.sort_values(col_name).iloc[0]]) - X_train[col_name].min()*model.coef_[col_index]\n",
    "plt.plot(new_x, intercept+new_x*model.coef_[col_index])\n",
    "\n",
    "plt.legend(['controlled model','true training','predicted training','predicted testing'])\n",
    "plt.xlabel(col_name)\n",
    "plt.ylabel('Reading 8 score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this plot, we also had to modify the predicted intercept. Since the intercept is typically the predicted value with all values being zero, we obviously can't use that as our intercept in plotting. Instead, we modified the intercept such that the first predicted point is exactly correct. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can also frame this as a classification problem. Instead of predicting the exact average score, can I predict if 8th graders in a state pass 'basic' level on the reading exam in a particular year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NAEP grade 8 reading cutoffs: basic 243, proficient 281\n",
    "y = df.loc[X.index]['AVG_READING_8_SCORE']>260"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm using the k-nearest neighbors classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "# confusion matrix shows the all results by how they were classified\n",
    "plot_confusion_matrix(model, X_test, y_test,\n",
    "                         cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy score\n",
    "accuracy_score(y_test, model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recall / sensitivity\n",
    "recall_score(y_test, model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision / specificity\n",
    "precision_score(y_test, model.predict(X_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
